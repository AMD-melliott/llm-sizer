models:
- hf_model_id: zai-org/GLM-4.5-Air
  tensor_parallel_size: 4
  batch_sizes:
  - 1
  - 8
  quantization: null
  output_lengths:
  - 256
  - 512
  dtype: float16
  container_name: vllm-inference
  input_lengths:
  - 256
  - 512
- hf_model_id: TheBloke/Llama-2-13B-chat-AWQ
  tensor_parallel_size: 1
  batch_sizes:
  - 1
  - 8
  - 16
  quantization: awq
  output_lengths:
  - 512
  dtype: float16
  container_name: vllm-quantized
  input_lengths:
  - 512
