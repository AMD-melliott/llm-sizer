models:
- hf_model_id: meta-llama/Llama-3.2-1B-Instruct
  tensor_parallel_size: 1
  batch_sizes:
  - 1
  - 8
  quantization: null
  output_lengths:
  - 1024
  kv_cache_dtype: fp8
  dtype: float16
  trust_remote_code: false
  container_name: vllm-inference
  input_lengths:
  - 1024
- hf_model_id: meta-llama/Llama-3.1-8B-Instruct
  tensor_parallel_size: 1
  batch_sizes:
  - 1
  - 8
  quantization: null
  output_lengths:
  - 1024
  kv_cache_dtype: fp8
  dtype: float16
  trust_remote_code: false
  container_name: vllm-inference
  input_lengths:
  - 1024
- hf_model_id: Qwen/Qwen2.5-7B-Instruct
  tensor_parallel_size: 1
  batch_sizes:
  - 1
  - 8
  quantization: null
  output_lengths:
  - 1024
  kv_cache_dtype: null
  dtype: float16
  trust_remote_code: false
  container_name: vllm-inference
  input_lengths:
  - 1024
- hf_model_id: mistralai/Mistral-7B-Instruct-v0.3
  tensor_parallel_size: 1
  batch_sizes:
  - 1
  - 8
  quantization: null
  output_lengths:
  - 1024
  kv_cache_dtype: null
  dtype: float16
  trust_remote_code: false
  container_name: vllm-inference
  input_lengths:
  - 1024
