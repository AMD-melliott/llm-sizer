{
  "gpus": [
    {
      "id": "mi355x",
      "vendor": "AMD",
      "name": "AMD Instinct MI355X",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 288,
      "memory_type": "HBM3e",
      "memory_bandwidth_gbps": 8000,
      "compute_tflops_fp16": 2300,
      "compute_tflops_fp8": 4600,
      "nvlink_bandwidth_gbps": 896,
      "pcie_gen": 5,
      "tdp_watts": 1000,
      "multi_gpu_capable": true,
      "release_year": 2025,
      "partitioning": {
        "supported": true,
        "modes": [
          {
            "mode": "SPX",
            "name": "Single Partition X-celerator",
            "description": "Full GPU resources (8 XCDs as single logical GPU)",
            "partitionCount": 1,
            "vramPerPartition": 288,
            "bandwidthPerPartition": 8000,
            "computeFP16PerPartition": 2300,
            "computeFP8PerPartition": 4600
          },
          {
            "mode": "DPX",
            "name": "Dual Partition Extended",
            "description": "2 isolated partitions",
            "partitionCount": 2,
            "vramPerPartition": 144,
            "bandwidthPerPartition": 4000,
            "computeFP16PerPartition": 1150,
            "computeFP8PerPartition": 2300
          },
          {
            "mode": "CPX",
            "name": "Core Partition Extended",
            "description": "8 partitions (each XCD as separate logical GPU)",
            "partitionCount": 8,
            "vramPerPartition": 36,
            "bandwidthPerPartition": 1000,
            "computeFP16PerPartition": 287.5,
            "computeFP8PerPartition": 575
          }
        ]
      }
    },
    {
      "id": "mi350x",
      "vendor": "AMD",
      "name": "AMD Instinct MI350X",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 288,
      "memory_type": "HBM3e",
      "memory_bandwidth_gbps": 8000,
      "compute_tflops_fp16": 2300,
      "compute_tflops_fp8": 4600,
      "pcie_gen": 5,
      "tdp_watts": 1000,
      "multi_gpu_capable": true,
      "release_year": 2025,
      "partitioning": {
        "supported": true,
        "modes": [
          {
            "mode": "SPX",
            "name": "Single Partition X-celerator",
            "description": "Full GPU resources (8 XCDs as single logical GPU)",
            "partitionCount": 1,
            "vramPerPartition": 288,
            "bandwidthPerPartition": 8000,
            "computeFP16PerPartition": 2300,
            "computeFP8PerPartition": 4600
          },
          {
            "mode": "DPX",
            "name": "Dual Partition Extended",
            "description": "2 isolated partitions",
            "partitionCount": 2,
            "vramPerPartition": 144,
            "bandwidthPerPartition": 4000,
            "computeFP16PerPartition": 1150,
            "computeFP8PerPartition": 2300
          },
          {
            "mode": "CPX",
            "name": "Core Partition Extended",
            "description": "8 partitions (each XCD as separate logical GPU)",
            "partitionCount": 8,
            "vramPerPartition": 36,
            "bandwidthPerPartition": 1000,
            "computeFP16PerPartition": 287.5,
            "computeFP8PerPartition": 575
          }
        ]
      }
    },
    {
      "id": "mi325x",
      "vendor": "AMD",
      "name": "AMD Instinct MI325X",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 256,
      "memory_type": "HBM3e",
      "memory_bandwidth_gbps": 6000,
      "compute_tflops_fp16": 1307,
      "compute_tflops_fp8": 2615,
      "nvlink_bandwidth_gbps": 896,
      "pcie_gen": 5,
      "tdp_watts": 1000,
      "multi_gpu_capable": true,
      "release_year": 2024,
      "partitioning": {
        "supported": true,
        "modes": [
          {
            "mode": "SPX",
            "name": "Single Partition X-celerator",
            "description": "Full GPU resources (8 XCDs as single logical GPU)",
            "partitionCount": 1,
            "vramPerPartition": 256,
            "bandwidthPerPartition": 6000,
            "computeFP16PerPartition": 1307,
            "computeFP8PerPartition": 2615
          },
          {
            "mode": "DPX",
            "name": "Dual Partition Extended",
            "description": "2 isolated partitions",
            "partitionCount": 2,
            "vramPerPartition": 128,
            "bandwidthPerPartition": 3000,
            "computeFP16PerPartition": 653.5,
            "computeFP8PerPartition": 1307.5
          },
          {
            "mode": "CPX",
            "name": "Core Partition Extended",
            "description": "8 partitions (each XCD as separate logical GPU)",
            "partitionCount": 8,
            "vramPerPartition": 32,
            "bandwidthPerPartition": 750,
            "computeFP16PerPartition": 163.4,
            "computeFP8PerPartition": 326.9
          }
        ]
      }
    },
    {
      "id": "mi300x",
      "vendor": "AMD",
      "name": "AMD Instinct MI300X",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 192,
      "memory_type": "HBM3",
      "memory_bandwidth_gbps": 5300,
      "compute_tflops_fp16": 1300,
      "compute_tflops_fp8": 2600,
      "nvlink_bandwidth_gbps": 896,
      "pcie_gen": 5,
      "tdp_watts": 750,
      "multi_gpu_capable": true,
      "release_year": 2023,
      "partitioning": {
        "supported": true,
        "modes": [
          {
            "mode": "SPX",
            "name": "Single Partition X-celerator",
            "description": "Full GPU resources (8 XCDs as single logical GPU)",
            "partitionCount": 1,
            "vramPerPartition": 192,
            "bandwidthPerPartition": 5300,
            "computeFP16PerPartition": 1300,
            "computeFP8PerPartition": 2600
          },
          {
            "mode": "DPX",
            "name": "Dual Partition Extended",
            "description": "2 isolated partitions",
            "partitionCount": 2,
            "vramPerPartition": 96,
            "bandwidthPerPartition": 2650,
            "computeFP16PerPartition": 650,
            "computeFP8PerPartition": 1300
          },
          {
            "mode": "CPX",
            "name": "Core Partition Extended",
            "description": "8 partitions (each XCD as separate logical GPU)",
            "partitionCount": 8,
            "vramPerPartition": 24,
            "bandwidthPerPartition": 662.5,
            "computeFP16PerPartition": 162.5,
            "computeFP8PerPartition": 325
          }
        ]
      }
    },
    {
      "id": "mi300a",
      "vendor": "AMD",
      "name": "AMD Instinct MI300A",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 128,
      "memory_type": "HBM3",
      "memory_bandwidth_gbps": 5300,
      "compute_tflops_fp16": 1300,
      "compute_tflops_fp8": 2600,
      "pcie_gen": 5,
      "tdp_watts": 760,
      "multi_gpu_capable": true,
      "release_year": 2023,
      "partitioning": {
        "supported": true,
        "modes": [
          {
            "mode": "SPX",
            "name": "Single Partition X-celerator",
            "description": "Full GPU resources",
            "partitionCount": 1,
            "vramPerPartition": 128,
            "bandwidthPerPartition": 5300,
            "computeFP16PerPartition": 1300,
            "computeFP8PerPartition": 2600
          },
          {
            "mode": "DPX",
            "name": "Dual Partition Extended",
            "description": "2 isolated partitions",
            "partitionCount": 2,
            "vramPerPartition": 64,
            "bandwidthPerPartition": 2650,
            "computeFP16PerPartition": 650,
            "computeFP8PerPartition": 1300
          },
          {
            "mode": "CPX",
            "name": "Core Partition Extended",
            "description": "4 partitions",
            "partitionCount": 4,
            "vramPerPartition": 32,
            "bandwidthPerPartition": 1325,
            "computeFP16PerPartition": 325,
            "computeFP8PerPartition": 650
          }
        ]
      }
    },
    {
      "id": "mi250x",
      "vendor": "AMD",
      "name": "AMD Instinct MI250X",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 128,
      "memory_type": "HBM2e",
      "memory_bandwidth_gbps": 3200,
      "compute_tflops_fp16": 383,
      "pcie_gen": 4,
      "tdp_watts": 560,
      "multi_gpu_capable": true,
      "release_year": 2021,
      "partitioning": {
        "supported": true,
        "modes": [
          {
            "mode": "SPX",
            "name": "Single Partition X-celerator",
            "description": "Full GPU resources",
            "partitionCount": 1,
            "vramPerPartition": 128,
            "bandwidthPerPartition": 3200,
            "computeFP16PerPartition": 383
          },
          {
            "mode": "DPX",
            "name": "Dual Partition Extended",
            "description": "2 isolated partitions",
            "partitionCount": 2,
            "vramPerPartition": 64,
            "bandwidthPerPartition": 1600,
            "computeFP16PerPartition": 191.5
          },
          {
            "mode": "CPX",
            "name": "Core Partition Extended",
            "description": "4 partitions",
            "partitionCount": 4,
            "vramPerPartition": 32,
            "bandwidthPerPartition": 800,
            "computeFP16PerPartition": 95.75
          }
        ]
      }
    },
    {
      "id": "mi210",
      "vendor": "AMD",
      "name": "AMD Instinct MI210",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 64,
      "memory_type": "HBM2e",
      "memory_bandwidth_gbps": 1638,
      "compute_tflops_fp16": 181,
      "pcie_gen": 4,
      "tdp_watts": 300,
      "multi_gpu_capable": true,
      "release_year": 2021,
      "partitioning": {
        "supported": true,
        "modes": [
          {
            "mode": "SPX",
            "name": "Single Partition X-celerator",
            "description": "Full GPU resources",
            "partitionCount": 1,
            "vramPerPartition": 64,
            "bandwidthPerPartition": 1638,
            "computeFP16PerPartition": 181
          },
          {
            "mode": "DPX",
            "name": "Dual Partition Extended",
            "description": "2 isolated partitions",
            "partitionCount": 2,
            "vramPerPartition": 32,
            "bandwidthPerPartition": 819,
            "computeFP16PerPartition": 90.5
          },
          {
            "mode": "CPX",
            "name": "Core Partition Extended",
            "description": "4 partitions",
            "partitionCount": 4,
            "vramPerPartition": 16,
            "bandwidthPerPartition": 409.5,
            "computeFP16PerPartition": 45.25
          }
        ]
      }
    },
    {
      "id": "b200",
      "vendor": "NVIDIA",
      "name": "NVIDIA B200",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 192,
      "memory_type": "HBM3e",
      "memory_bandwidth_gbps": 8000,
      "compute_tflops_fp16": 2250,
      "compute_tflops_fp8": 4500,
      "nvlink_bandwidth_gbps": 1800,
      "pcie_gen": 5,
      "tdp_watts": 1000,
      "multi_gpu_capable": true,
      "release_year": 2025
    },
    {
      "id": "h200",
      "vendor": "NVIDIA",
      "name": "NVIDIA H200",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 141,
      "memory_type": "HBM3e",
      "memory_bandwidth_gbps": 4800,
      "compute_tflops_fp16": 989,
      "compute_tflops_fp8": 1979,
      "nvlink_bandwidth_gbps": 900,
      "pcie_gen": 5,
      "tdp_watts": 700,
      "multi_gpu_capable": true,
      "release_year": 2024
    },
    {
      "id": "h100-sxm",
      "vendor": "NVIDIA",
      "name": "NVIDIA H100 SXM5",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 80,
      "memory_type": "HBM3",
      "memory_bandwidth_gbps": 3350,
      "compute_tflops_fp16": 989,
      "compute_tflops_fp8": 1979,
      "nvlink_bandwidth_gbps": 900,
      "pcie_gen": 5,
      "tdp_watts": 700,
      "multi_gpu_capable": true,
      "release_year": 2022
    },
    {
      "id": "h100-pcie",
      "vendor": "NVIDIA",
      "name": "NVIDIA H100 PCIe",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 80,
      "memory_type": "HBM3",
      "memory_bandwidth_gbps": 2000,
      "compute_tflops_fp16": 756,
      "compute_tflops_fp8": 1513,
      "pcie_gen": 5,
      "tdp_watts": 350,
      "multi_gpu_capable": true,
      "release_year": 2022
    },
    {
      "id": "h100-nvl",
      "vendor": "NVIDIA",
      "name": "NVIDIA H100 NVL",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 94,
      "memory_type": "HBM3",
      "memory_bandwidth_gbps": 3900,
      "compute_tflops_fp16": 989,
      "compute_tflops_fp8": 1979,
      "nvlink_bandwidth_gbps": 900,
      "pcie_gen": 5,
      "tdp_watts": 450,
      "multi_gpu_capable": true,
      "release_year": 2023
    },
    {
      "id": "a100-80gb",
      "vendor": "NVIDIA",
      "name": "NVIDIA A100 80GB",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 80,
      "memory_type": "HBM2e",
      "memory_bandwidth_gbps": 2039,
      "compute_tflops_fp16": 312,
      "nvlink_bandwidth_gbps": 600,
      "pcie_gen": 4,
      "tdp_watts": 400,
      "multi_gpu_capable": true,
      "release_year": 2021
    },
    {
      "id": "a100-40gb",
      "vendor": "NVIDIA",
      "name": "NVIDIA A100 40GB",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 40,
      "memory_type": "HBM2e",
      "memory_bandwidth_gbps": 1555,
      "compute_tflops_fp16": 312,
      "nvlink_bandwidth_gbps": 600,
      "pcie_gen": 4,
      "tdp_watts": 400,
      "multi_gpu_capable": true,
      "release_year": 2020
    },
    {
      "id": "a40",
      "vendor": "NVIDIA",
      "name": "NVIDIA A40",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 48,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 696,
      "compute_tflops_fp16": 149.7,
      "nvlink_bandwidth_gbps": 112.5,
      "pcie_gen": 4,
      "tdp_watts": 300,
      "multi_gpu_capable": true,
      "release_year": 2020
    },
    {
      "id": "a30",
      "vendor": "NVIDIA",
      "name": "NVIDIA A30",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 24,
      "memory_type": "HBM2",
      "memory_bandwidth_gbps": 933,
      "compute_tflops_fp16": 165,
      "compute_tflops_fp8": 330,
      "pcie_gen": 4,
      "tdp_watts": 165,
      "multi_gpu_capable": true,
      "release_year": 2021
    },
    {
      "id": "l40s",
      "vendor": "NVIDIA",
      "name": "NVIDIA L40S",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 48,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 864,
      "compute_tflops_fp16": 366,
      "compute_tflops_fp8": 733,
      "pcie_gen": 4,
      "tdp_watts": 350,
      "multi_gpu_capable": true,
      "release_year": 2023
    },
    {
      "id": "l4",
      "vendor": "NVIDIA",
      "name": "NVIDIA L4",
      "category": "enterprise",
      "tier": "datacenter",
      "vram_gb": 24,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 300,
      "compute_tflops_fp16": 121,
      "compute_tflops_fp8": 242,
      "pcie_gen": 4,
      "tdp_watts": 72,
      "multi_gpu_capable": false,
      "release_year": 2023
    },
    {
      "id": "radeon-pro-w7900",
      "vendor": "AMD",
      "name": "AMD Radeon PRO W7900",
      "category": "professional",
      "tier": "professional",
      "vram_gb": 48,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 864,
      "compute_tflops_fp16": 123,
      "pcie_gen": 4,
      "tdp_watts": 295,
      "multi_gpu_capable": true,
      "release_year": 2023
    },
    {
      "id": "radeon-pro-w7800",
      "vendor": "AMD",
      "name": "AMD Radeon PRO W7800",
      "category": "professional",
      "tier": "professional",
      "vram_gb": 32,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 576,
      "compute_tflops_fp16": 90.4,
      "pcie_gen": 4,
      "tdp_watts": 260,
      "multi_gpu_capable": true,
      "release_year": 2023
    },
    {
      "id": "radeon-pro-w7700",
      "vendor": "AMD",
      "name": "AMD Radeon PRO W7700",
      "category": "professional",
      "tier": "professional",
      "vram_gb": 16,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 384,
      "compute_tflops_fp16": 63.9,
      "pcie_gen": 4,
      "tdp_watts": 190,
      "multi_gpu_capable": true,
      "release_year": 2023
    },
    {
      "id": "rtx-6000-ada",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 6000 Ada",
      "category": "professional",
      "tier": "professional",
      "vram_gb": 48,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 960,
      "compute_tflops_fp16": 91.1,
      "pcie_gen": 4,
      "tdp_watts": 300,
      "multi_gpu_capable": false,
      "release_year": 2023
    },
    {
      "id": "rtx-a6000",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX A6000",
      "category": "consumer",
      "tier": "professional",
      "vram_gb": 48,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 768,
      "compute_tflops_fp16": 77.1,
      "nvlink_bandwidth_gbps": 112.5,
      "pcie_gen": 4,
      "tdp_watts": 300,
      "multi_gpu_capable": true,
      "release_year": 2020
    },
    {
      "id": "rtx-a5000",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX A5000",
      "category": "consumer",
      "tier": "professional",
      "vram_gb": 24,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 768,
      "compute_tflops_fp16": 54.2,
      "nvlink_bandwidth_gbps": 112.5,
      "pcie_gen": 4,
      "tdp_watts": 230,
      "multi_gpu_capable": true,
      "release_year": 2021
    },
    {
      "id": "rtx-a4000",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX A4000",
      "category": "consumer",
      "tier": "professional",
      "vram_gb": 16,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 448,
      "compute_tflops_fp16": 38.7,
      "pcie_gen": 4,
      "tdp_watts": 140,
      "multi_gpu_capable": false,
      "release_year": 2021
    },
    {
      "id": "rx-7900-xtx",
      "vendor": "AMD",
      "name": "AMD Radeon RX 7900 XTX",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 24,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 960,
      "compute_tflops_fp16": 122,
      "pcie_gen": 4,
      "tdp_watts": 355,
      "multi_gpu_capable": false,
      "release_year": 2022
    },
    {
      "id": "rx-7900-xt",
      "vendor": "AMD",
      "name": "AMD Radeon RX 7900 XT",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 20,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 800,
      "compute_tflops_fp16": 103,
      "pcie_gen": 4,
      "tdp_watts": 315,
      "multi_gpu_capable": false,
      "release_year": 2022
    },
    {
      "id": "rx-7900-gre",
      "vendor": "AMD",
      "name": "AMD Radeon RX 7900 GRE",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 16,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 576,
      "compute_tflops_fp16": 103.2,
      "pcie_gen": 4,
      "tdp_watts": 260,
      "multi_gpu_capable": false,
      "release_year": 2023
    },
    {
      "id": "rx-7800-xt",
      "vendor": "AMD",
      "name": "AMD Radeon RX 7800 XT",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 16,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 624,
      "compute_tflops_fp16": 74.6,
      "pcie_gen": 4,
      "tdp_watts": 263,
      "multi_gpu_capable": false,
      "release_year": 2023
    },
    {
      "id": "rx-7700-xt",
      "vendor": "AMD",
      "name": "AMD Radeon RX 7700 XT",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 12,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 432,
      "compute_tflops_fp16": 70.2,
      "pcie_gen": 4,
      "tdp_watts": 245,
      "multi_gpu_capable": false,
      "release_year": 2023
    },
    {
      "id": "rtx-4090",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 4090",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 24,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 1008,
      "compute_tflops_fp16": 82.6,
      "compute_tflops_fp8": 165.2,
      "pcie_gen": 4,
      "tdp_watts": 450,
      "multi_gpu_capable": false,
      "release_year": 2022
    },
    {
      "id": "rtx-4080-super",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 4080 Super",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 16,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 736,
      "compute_tflops_fp16": 52.2,
      "compute_tflops_fp8": 104.4,
      "pcie_gen": 4,
      "tdp_watts": 320,
      "multi_gpu_capable": false,
      "release_year": 2024
    },
    {
      "id": "rtx-4080",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 4080",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 16,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 717,
      "compute_tflops_fp16": 48.7,
      "compute_tflops_fp8": 97.5,
      "pcie_gen": 4,
      "tdp_watts": 320,
      "multi_gpu_capable": false,
      "release_year": 2022
    },
    {
      "id": "rtx-4070-ti-super",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 4070 Ti Super",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 16,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 672,
      "compute_tflops_fp16": 44.1,
      "compute_tflops_fp8": 88.2,
      "pcie_gen": 4,
      "tdp_watts": 285,
      "multi_gpu_capable": false,
      "release_year": 2024
    },
    {
      "id": "rtx-4070-ti",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 4070 Ti",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 12,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 504,
      "compute_tflops_fp16": 40.1,
      "compute_tflops_fp8": 80.2,
      "pcie_gen": 4,
      "tdp_watts": 285,
      "multi_gpu_capable": false,
      "release_year": 2023
    },
    {
      "id": "rtx-3090-ti",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 3090 Ti",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 24,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 1008,
      "compute_tflops_fp16": 40,
      "pcie_gen": 4,
      "tdp_watts": 450,
      "multi_gpu_capable": false,
      "release_year": 2022
    },
    {
      "id": "rtx-3090",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 3090",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 24,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 936,
      "compute_tflops_fp16": 35.6,
      "pcie_gen": 4,
      "tdp_watts": 350,
      "multi_gpu_capable": false,
      "release_year": 2020
    },
    {
      "id": "rtx-3080-ti",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 3080 Ti",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 12,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 912,
      "compute_tflops_fp16": 34.1,
      "pcie_gen": 4,
      "tdp_watts": 350,
      "multi_gpu_capable": false,
      "release_year": 2021
    },
    {
      "id": "rtx-3080",
      "vendor": "NVIDIA",
      "name": "NVIDIA RTX 3080",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 10,
      "memory_type": "GDDR6X",
      "memory_bandwidth_gbps": 760,
      "compute_tflops_fp16": 29.8,
      "pcie_gen": 4,
      "tdp_watts": 320,
      "multi_gpu_capable": false,
      "release_year": 2020
    },
    {
      "id": "strix-halo-395",
      "vendor": "AMD",
      "name": "AMD Ryzen AI Max+ 395 (Strix Halo)",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 96,
      "memory_type": "LPDDR5X-8000",
      "memory_bandwidth_gbps": 256,
      "compute_tflops_fp16": 51.2,
      "pcie_gen": 5,
      "tdp_watts": 120,
      "multi_gpu_capable": false,
      "release_year": 2025
    },
    {
      "id": "strix-halo-390",
      "vendor": "AMD",
      "name": "AMD Ryzen AI Max PRO 390 (Strix Halo)",
      "category": "consumer",
      "tier": "consumer",
      "vram_gb": 96,
      "memory_type": "LPDDR5X-8000",
      "memory_bandwidth_gbps": 256,
      "compute_tflops_fp16": 41,
      "pcie_gen": 5,
      "tdp_watts": 120,
      "multi_gpu_capable": false,
      "release_year": 2025
    },
    {
      "id": "custom",
      "vendor": "Custom",
      "name": "Custom GPU",
      "category": "consumer",
      "tier": "custom",
      "vram_gb": 24,
      "memory_type": "GDDR6",
      "memory_bandwidth_gbps": 1000,
      "compute_tflops_fp16": 100,
      "compute_tflops_fp8": 200,
      "pcie_gen": 4,
      "tdp_watts": 300,
      "multi_gpu_capable": false,
      "release_year": 2023
    }
  ]
}